{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from functools import partial\n",
    "import functools\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import yaml\n",
    "from joblib import cpu_count\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "from models.fpn_inception import FPNInception\n",
    "from schedulers import LinearDecay\n",
    "\n",
    "from dataset import PairedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.setNumThreads(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_layer(norm_type='instance'):#归一化\n",
    "    if norm_type == 'batch':\n",
    "        norm_layer = functools.partial(nn.BatchNorm2d, affine=True)\n",
    "    elif norm_type == 'instance':\n",
    "        norm_layer = functools.partial(nn.InstanceNorm2d, affine=False, track_running_stats=True)\n",
    "    else:\n",
    "        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n",
    "    return norm_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成器的感知loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptualLoss():\n",
    "\n",
    "    def contentFunc(self):\n",
    "        conv_3_3_layer = 14\n",
    "        cnn = models.vgg19(pretrained=True).features\n",
    "        #cnn = cnn.cuda()\n",
    "        model = nn.Sequential()\n",
    "        #model = model.cuda()\n",
    "        model = model.eval()\n",
    "        for i, layer in enumerate(list(cnn)):\n",
    "            model.add_module(str(i), layer)\n",
    "            if i == conv_3_3_layer:\n",
    "                break\n",
    "        return model\n",
    "\n",
    "    def initialize(self, loss):\n",
    "        with torch.no_grad():\n",
    "            self.criterion = loss\n",
    "            self.contentFunc = self.contentFunc()\n",
    "            self.transform = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    def get_loss(self, fakeIm, realIm):\n",
    "        fakeIm = (fakeIm + 1) / 2.0\n",
    "        realIm = (realIm + 1) / 2.0\n",
    "        fakeIm[0, :, :, :] = self.transform(fakeIm[0, :, :, :])\n",
    "        realIm[0, :, :, :] = self.transform(realIm[0, :, :, :])\n",
    "        f_fake = self.contentFunc.forward(fakeIm)\n",
    "        f_real = self.contentFunc.forward(realIm)\n",
    "        f_real_no_grad = f_real.detach()\n",
    "        loss = self.criterion(f_fake, f_real_no_grad)\n",
    "        return 0.006 * torch.mean(loss) + 0.5 * nn.MSELoss()(fakeIm, realIm)\n",
    "\n",
    "    def __call__(self, fakeIm, realIm):\n",
    "        return self.get_loss(fakeIm, realIm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 判别器的WGAN-GP loss\n",
    "\n",
    "$$L=\\underset{\\tilde{\\boldsymbol{x}} \\sim \\mathbb{P}_{g}}{\\mathbb{E}}[D(\\tilde{\\boldsymbol{x}})]-\\underset{\\boldsymbol{x} \\sim \\mathbb{P}_{r}}{\\mathbb{E}}[D(\\boldsymbol{x})]+\\lambda \\underset{\\hat{\\boldsymbol{x}} \\sim \\mathbb{P}_{\\hat{\\boldsymbol{x}}}}{\\mathbb{E}}\\left[\\left(\\left\\|\\nabla_{\\hat{\\boldsymbol{x}}} D(\\hat{\\boldsymbol{x}})\\right\\|_{2}-1\\right)^{2}\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# class GANLoss(nn.Module):\n",
    "#     def __init__(self, use_l1=True, target_real_label=1.0, target_fake_label=0.0,\n",
    "#                  tensor=torch.FloatTensor):\n",
    "#         super(GANLoss, self).__init__()\n",
    "#         self.real_label = target_real_label\n",
    "#         self.fake_label = target_fake_label\n",
    "#         self.real_label_var = None\n",
    "#         self.fake_label_var = None\n",
    "#         self.Tensor = tensor\n",
    "#         if use_l1:\n",
    "#             self.loss = nn.L1Loss()\n",
    "#         else:\n",
    "#             self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "#     def get_target_tensor(self, input, target_is_real):\n",
    "#         if target_is_real:\n",
    "#             create_label = ((self.real_label_var is None) or\n",
    "#                             (self.real_label_var.numel() != input.numel()))\n",
    "#             if create_label:\n",
    "#                 real_tensor = self.Tensor(input.size()).fill_(self.real_label)\n",
    "#                 self.real_label_var = Variable(real_tensor, requires_grad=False)\n",
    "#             target_tensor = self.real_label_var\n",
    "#         else:\n",
    "#             create_label = ((self.fake_label_var is None) or\n",
    "#                             (self.fake_label_var.numel() != input.numel()))\n",
    "#             if create_label:\n",
    "#                 fake_tensor = self.Tensor(input.size()).fill_(self.fake_label)\n",
    "#                 self.fake_label_var = Variable(fake_tensor, requires_grad=False)\n",
    "#             target_tensor = self.fake_label_var\n",
    "#         return target_tensor\n",
    "\n",
    "#     def __call__(self, input, target_is_real):\n",
    "        \n",
    "#         target_tensor = self.get_target_tensor(input, target_is_real)\n",
    "#         return self.loss(input, target_tensor)\n",
    "\n",
    "\n",
    "\n",
    "class DiscLoss(nn.Module):\n",
    "    def name(self):\n",
    "        return 'DiscLoss'\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DiscLoss, self).__init__()\n",
    "\n",
    "        #self.criterionGAN = GANLoss(use_l1=False)\n",
    "        #self.fake_AB_pool = ImagePool(50)\n",
    "\n",
    "#     def get_g_loss(self, net, fakeB, realB):\n",
    "#         # First, G(A) should fake the discriminator\n",
    "#         pred_fake = net.forward(fakeB)\n",
    "#         return self.criterionGAN(pred_fake, 1)\n",
    "\n",
    "    #def get_loss(self, net, fakeB, realB):\n",
    "        # Fake\n",
    "        # stop backprop to the generator by detaching fake_B\n",
    "        # Generated Image Disc Output should be close to zero\n",
    "#         self.pred_fake = net.forward(fakeB.detach())\n",
    "\n",
    "#         self.loss_D_fake = self.criterionGAN(self.pred_fake, 0)\n",
    "\n",
    "#         # Real\n",
    "#         self.pred_real = net.forward(realB)\n",
    "#         self.loss_D_real = self.criterionGAN(self.pred_real, 1)\n",
    "\n",
    "#         # Combined loss\n",
    "#         self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n",
    "#         return self.loss_D\n",
    "\n",
    "    def __call__(self, net, fakeB, realB):\n",
    "        \n",
    "        return self.get_loss(net, fakeB, realB)\n",
    "    \n",
    "    \n",
    "    \n",
    "# class DiscLossLS(DiscLoss):\n",
    "#     def name(self):\n",
    "#         return 'DiscLossLS'\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super(DiscLossLS, self).__init__()\n",
    "#         self.criterionGAN = GANLoss(use_l1=True)\n",
    "\n",
    "#     def get_g_loss(self, net, fakeB, realB):\n",
    "#         return DiscLoss.get_g_loss(self, net, fakeB)\n",
    "\n",
    "#     def get_loss(self, net, fakeB, realB):\n",
    "#         return DiscLoss.get_loss(self, net, fakeB, realB)\n",
    "    \n",
    "    \n",
    "class DiscLossWGANGP(DiscLoss):\n",
    "    def name(self):\n",
    "        return 'DiscLossWGAN-GP'\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DiscLossWGANGP, self).__init__()\n",
    "        self.LAMBDA = 10\n",
    "\n",
    "    def get_g_loss(self, net, fakeB, realB):\n",
    "        # First, G(A) should fake the discriminator\n",
    "        self.D_fake = net.forward(fakeB)\n",
    "        return -self.D_fake.mean()\n",
    "\n",
    "    def calc_gradient_penalty(self, netD, real_data, fake_data):\n",
    "        alpha = torch.rand(1, 1)\n",
    "        alpha = alpha.expand(real_data.size())\n",
    "\n",
    "        interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "\n",
    "        interpolates = Variable(interpolates, requires_grad=True)\n",
    "\n",
    "        disc_interpolates = netD.forward(interpolates)\n",
    "\n",
    "\n",
    "        gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                                  grad_outputs=torch.ones(disc_interpolates.size()),\n",
    "                                  create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * self.LAMBDA\n",
    "        return gradient_penalty\n",
    "\n",
    "    def get_loss(self, net, fakeB, realB):\n",
    "\n",
    "        self.D_fake = net.forward(fakeB.detach())\n",
    "        self.D_fake = self.D_fake.mean()\n",
    "        \n",
    "\n",
    "        # Real\n",
    "        self.D_real = net.forward(realB)\n",
    "        self.D_real = self.D_real.mean()\n",
    "        \n",
    "\n",
    "        # Combined loss\n",
    "        self.loss_D = self.D_fake - self.D_real\n",
    "\n",
    "        gradient_penalty = self.calc_gradient_penalty(net, realB.data, fakeB.data)\n",
    "\n",
    "        return self.loss_D + gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model):\n",
    "    \n",
    "    content_loss = PerceptualLoss()\n",
    "    content_loss.initialize(nn.MSELoss())\n",
    "\n",
    "    disc_loss = DiscLossWGANGP()\n",
    "\n",
    "\n",
    "    return content_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成器和判别器的网络\n",
    "\n",
    "**判别器网络**：\n",
    ">    \n",
    "    {'patch': \n",
    "          (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
    "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "          (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
    "          (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
    "          (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "          (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
    "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
    "          (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "          (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
    "          (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
    "          (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "          (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
    "     , 'full': \n",
    "          (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
    "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "          (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
    "          (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
    "          (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "          (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
    "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
    "          (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "          (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
    "          (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
    "          (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "          (11): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
    "          (12): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
    "          (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "          (14): Conv2d(512, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
    "          (15): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
    "          (16): LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "          (17): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the PatchGAN discriminator with the specified arguments.\n",
    "class NLayerDiscriminator(nn.Module):\n",
    "    def __init__(self, input_nc=3, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d, use_sigmoid=False, use_parallel=True):\n",
    "        super(NLayerDiscriminator, self).__init__()\n",
    "        self.use_parallel = use_parallel\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        kw = 4\n",
    "        padw = int(np.ceil((kw-1)/2))\n",
    "        sequence = [\n",
    "            nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        nf_mult = 1\n",
    "        for n in range(1, n_layers):\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2**n, 8)\n",
    "            sequence += [\n",
    "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult,\n",
    "                          kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
    "                norm_layer(ndf * nf_mult),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]\n",
    "\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2**n_layers, 8)\n",
    "        sequence += [\n",
    "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult,\n",
    "                      kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
    "            norm_layer(ndf * nf_mult),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]\n",
    "\n",
    "        if use_sigmoid:\n",
    "            sequence += [nn.Sigmoid()]\n",
    "\n",
    "        self.model = nn.Sequential(*sequence)\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(model_config):\n",
    "    model_g = FPNInception(norm_layer=get_norm_layer(norm_type=model_config['norm_layer']))\n",
    "\n",
    "    return nn.DataParallel(model_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator(model_config):\n",
    "    patch_gan = NLayerDiscriminator(n_layers=model_config['d_layers'],\n",
    "                                        norm_layer=get_norm_layer(norm_type=model_config['norm_layer']),\n",
    "                                        use_sigmoid=False)\n",
    "    patch_gan = nn.DataParallel(patch_gan)\n",
    "    \n",
    "    full_gan = NLayerDiscriminator(n_layers=5,\n",
    "                                  norm_layer=get_norm_layer(norm_type=model_config['norm_layer']),\n",
    "                                  use_sigmoid=False)\n",
    "    full_gan = nn.DataParallel(full_gan)\n",
    "    \n",
    "    model_d = {'patch': patch_gan,\n",
    "               'full': full_gan}\n",
    "\n",
    "\n",
    "    return model_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nets(model_config):\n",
    "    return get_generator(model_config), get_discriminator(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANFactory:\n",
    "    factories = {}\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def add_factory(gan_id, model_factory):\n",
    "        GANFactory.factories.put[gan_id] = model_factory\n",
    "\n",
    "    add_factory = staticmethod(add_factory)\n",
    "\n",
    "    # A Template Method:\n",
    "\n",
    "    def create_model(gan_id, net_d=None, criterion=None):\n",
    "        if gan_id not in GANFactory.factories:\n",
    "            GANFactory.factories[gan_id] = \\\n",
    "                eval(gan_id + '.Factory()')\n",
    "        return GANFactory.factories[gan_id].create(net_d, criterion)\n",
    "\n",
    "    create_model = staticmethod(create_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANTrainer(object):\n",
    "    def __init__(self, net_d, criterion):\n",
    "        self.net_d = net_d\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def loss_d(self, pred, gt):\n",
    "        pass\n",
    "\n",
    "    def loss_g(self, pred, gt):\n",
    "        pass\n",
    "\n",
    "    def get_params(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss_d会call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleGAN(GANTrainer):\n",
    "    def __init__(self, net_d, criterion):\n",
    "        GANTrainer.__init__(self, net_d, criterion)\n",
    "        self.patch_d = net_d['patch']\n",
    "        self.full_d = net_d['full']\n",
    "        self.full_criterion = copy.deepcopy(criterion)\n",
    "\n",
    "    def loss_d(self, pred, gt):##pred：fake；gt：real\n",
    "        return (self.criterion(self.patch_d, pred, gt) + self.full_criterion(self.full_d, pred, gt)) / 2\n",
    "\n",
    "    def loss_g(self, pred, gt):\n",
    "        return (self.criterion.get_g_loss(self.patch_d, pred, gt) + self.full_criterion.get_g_loss(self.full_d, pred,\n",
    "                                                                                                  gt)) / 2\n",
    "\n",
    "    def get_params(self):\n",
    "        return list(self.patch_d.parameters()) + list(self.full_d.parameters())\n",
    "\n",
    "    class Factory:\n",
    "        @staticmethod\n",
    "        def create(net_d, criterion): return DoubleGAN(net_d, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeblurModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeblurModel, self).__init__()\n",
    "\n",
    "    def get_input(self, data):\n",
    "        img = data['a']\n",
    "        inputs = img\n",
    "        targets = data['b']\n",
    "\n",
    "        return inputs, targets\n",
    "\n",
    "    def tensor2im(self, image_tensor, imtype=np.uint8):\n",
    "        image_numpy = image_tensor[0].cpu().float().numpy()\n",
    "        image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0\n",
    "        return image_numpy.astype(imtype)\n",
    "\n",
    "\n",
    "def get_model(model_config):\n",
    "    return DeblurModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, config, train: DataLoader, val: DataLoader):\n",
    "        self.config = config\n",
    "        self.train_dataset = train\n",
    "        self.val_dataset = val\n",
    "        self.adv_lambda = config['model']['adv_lambda']\n",
    "        self.warmup_epochs = config['warmup_num']\n",
    "\n",
    "    def train(self):\n",
    "        self._init_params()\n",
    "\n",
    "        for epoch in range(0, 1):\n",
    "            if (epoch == self.warmup_epochs) and not (self.warmup_epochs == 0):\n",
    "                self.netG.module.unfreeze()\n",
    "                self.optimizer_G = self._get_optim(self.netG.parameters())\n",
    "                self.scheduler_G = self._get_scheduler(self.optimizer_G)\n",
    "            self._run_epoch(epoch)\n",
    "            self._validate(epoch)\n",
    "            self.scheduler_G.step()\n",
    "            self.scheduler_D.step()\n",
    "         \n",
    "\n",
    "    def _run_epoch(self, epoch):\n",
    "        \n",
    "        for param_group in self.optimizer_G.param_groups:\n",
    "            lr = param_group['lr']\n",
    "\n",
    "        epoch_size = config.get('train_batches_per_epoch') or len(self.train_dataset)\n",
    "        tq = tqdm.tqdm(self.train_dataset, total=epoch_size)\n",
    "        tq.set_description('Epoch {}, lr {}'.format(epoch, lr))\n",
    "        i = 0\n",
    "\n",
    "        for data in tq:\n",
    "            inputs, targets = self.model.get_input(data)\n",
    "            outputs = self.netG(inputs) #outputs为经过生产器生成的\n",
    "            \n",
    "            loss_D = self._update_d(outputs, targets)#更新判别器的参数，并返回loss\n",
    "            \n",
    "            self.optimizer_G.zero_grad()\n",
    "            \n",
    "            loss_content = self.criterionG(outputs, targets)#感知loss\n",
    "            loss_adv = self.adv_trainer.loss_g(outputs, targets)#生成器的loss\n",
    "            loss_G = loss_content + self.adv_lambda * loss_adv\n",
    "            \n",
    "            loss_G.backward()#生成器的loss反向传播\n",
    "            self.optimizer_G.step()#更新生成器的参数\n",
    "\n",
    "            i += 1\n",
    "            if i > epoch_size:\n",
    "                break\n",
    "        tq.close()\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    def _validate(self, epoch):\n",
    "        \n",
    "        epoch_size = config.get('val_batches_per_epoch') or len(self.val_dataset)\n",
    "        tq = tqdm.tqdm(self.val_dataset, total=epoch_size)\n",
    "        tq.set_description('Validation')\n",
    "        i = 0\n",
    "        for data in tq:\n",
    "            inputs, targets = self.model.get_input(data)\n",
    "            outputs = self.netG(inputs)\n",
    "            loss_content = self.criterionG(outputs, targets)\n",
    "            loss_adv = self.adv_trainer.loss_g(outputs, targets)\n",
    "            loss_G = loss_content + self.adv_lambda * loss_adv\n",
    "            \n",
    "            \n",
    "            \n",
    "            i += 1\n",
    "            if i > epoch_size:\n",
    "                break\n",
    "        tq.close()\n",
    "        \n",
    "\n",
    "    def _update_d(self, outputs, targets):\n",
    "        \n",
    "        self.optimizer_D.zero_grad()\n",
    "        loss_D = self.adv_lambda * self.adv_trainer.loss_d(outputs, targets)#计算判别器的loss\n",
    "        \n",
    "        loss_D.backward(retain_graph=True)#判别器的loss反向传播求梯度\n",
    "        self.optimizer_D.step()#更新判别器的各个参数\n",
    "        \n",
    "        return loss_D.item()\n",
    "\n",
    "    def _get_optim(self, params):\n",
    "        optimizer = optim.Adam(params, lr=self.config['optimizer']['lr'])\n",
    "        \n",
    "        return optimizer\n",
    "\n",
    "    def _get_scheduler(self, optimizer):\n",
    "        scheduler = LinearDecay(optimizer,\n",
    "                                    min_lr=self.config['scheduler']['min_lr'],\n",
    "                                    num_epochs=self.config['num_epochs'],\n",
    "                                    start_epoch=self.config['scheduler']['start_epoch'])\n",
    "        return scheduler\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_adversarial_trainer(d_name, net_d, criterion_d):\n",
    "        \n",
    "        return GANFactory.create_model('DoubleGAN', net_d, criterion_d)\n",
    "        \n",
    "\n",
    "    def _init_params(self):\n",
    "        self.criterionG, criterionD = get_loss(self.config['model'])\n",
    "\n",
    "        self.netG, netD = get_nets(self.config['model'])\n",
    "        \n",
    "        #self.netG.cuda()\n",
    "        self.adv_trainer = self._get_adversarial_trainer(self.config['model']['d_name'], netD, criterionD)#double_gan\n",
    "        self.model = get_model(self.config['model'])\n",
    "        \n",
    "        self.optimizer_G = self._get_optim(filter(lambda p: p.requires_grad, self.netG.parameters()))\n",
    "        self.optimizer_D = self._get_optim(self.adv_trainer.get_params())\n",
    "        self.scheduler_G = self._get_scheduler(self.optimizer_G)\n",
    "        self.scheduler_D = self._get_scheduler(self.optimizer_D)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1225 00:43:49.299263 14679 warnings.py:110] /Users/llliuer/Desktop/大三上/创新实践/图像修复/code/MY_DeblurGANv2/venv/lib/python3.7/site-packages/ipykernel_launcher.py:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n",
      "\n",
      "I1225 00:43:49.310564 14679 dataset.py:28] Subsampling buckets from 0 to 90.0, total buckets number is 100\n",
      "I1225 00:43:49.311258 14679 dataset.py:71] Dataset has been created with 16 samples\n",
      "I1225 00:43:49.312687 14679 dataset.py:28] Subsampling buckets from 90.0 to 100, total buckets number is 100\n",
      "I1225 00:43:49.313170 14679 dataset.py:71] Dataset has been created with 4 samples\n",
      "Epoch 0, lr 0.0001:   0%|          | 0/1000 [00:00<?, ?it/s]W1225 00:43:52.366501 14679 warnings.py:110] /Users/llliuer/Desktop/大三上/创新实践/图像修复/code/MY_DeblurGANv2/venv/lib/python3.7/site-packages/torch/nn/functional.py:2404: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "\n",
      "Epoch 0, lr 0.0001:   0%|          | 2/1000 [00:12<1:45:34,  6.35s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c413fa064640>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-619debfe0fa3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_G\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_optim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler_G\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_G\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-619debfe0fa3>\u001b[0m in \u001b[0;36m_run_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#outputs为经过生产器生成的\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mloss_D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#更新判别器的参数，并返回loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/大三上/创新实践/图像修复/code/MY_DeblurGANv2/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/大三上/创新实践/图像修复/code/MY_DeblurGANv2/venv/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/大三上/创新实践/图像修复/code/MY_DeblurGANv2/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/大三上/创新实践/图像修复/code/MY_DeblurGANv2/DeblurGANv2-master/models/fpn_inception.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# 提取特征层\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mmap0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m#对不同的特征上采样\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/大三上/创新实践/图像修复/code/MY_DeblurGANv2/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/大三上/创新实践/图像修复/code/MY_DeblurGANv2/DeblurGANv2-master/models/fpn_inception.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mmap4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlateral4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mmap3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtd1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlateral3\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nearest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mmap2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtd2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlateral2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"reflect\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nearest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mmap1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtd3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlateral1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nearest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlateral0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"reflect\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/大三上/创新实践/图像修复/code/MY_DeblurGANv2/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/大三上/创新实践/图像修复/code/MY_DeblurGANv2/venv/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/大三上/创新实践/图像修复/code/MY_DeblurGANv2/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/大三上/创新实践/图像修复/code/MY_DeblurGANv2/venv/lib/python3.7/site-packages/torch/nn/modules/instancenorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     47\u001b[0m         return F.instance_norm(\n\u001b[1;32m     48\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             self.training or not self.track_running_stats, self.momentum, self.eps)\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/大三上/创新实践/图像修复/code/MY_DeblurGANv2/venv/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36minstance_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, use_input_stats, momentum, eps)\u001b[0m\n\u001b[1;32m   1683\u001b[0m     return torch.instance_norm(\n\u001b[1;32m   1684\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m         \u001b[0muse_input_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m     )\n\u001b[1;32m   1687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open('config/config.yaml', 'r') as f:\n",
    "    config = yaml.load(f)\n",
    "\n",
    "batch_size = config.pop('batch_size')\n",
    "get_dataloader = partial(DataLoader, batch_size=batch_size, num_workers=cpu_count(), shuffle=True, drop_last=True)#简单总结functools.partial的作用就是，把一个函数的某些参数给固定住（也就是设置默认值），返回一个新的函数，调用这个新函数会更简单。\n",
    "\n",
    "datasets = map(config.pop, ('train', 'val'))\n",
    "datasets = map(PairedDataset.from_config, datasets)\n",
    "train, val = map(get_dataloader, datasets)\n",
    "trainer = Trainer(config, train=train, val=val)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
